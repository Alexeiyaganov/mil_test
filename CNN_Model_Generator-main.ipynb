{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b70e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e5343",
   "metadata": {},
   "source": [
    "Берем картинки для тестирования из произвольного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9585f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44baa73f",
   "metadata": {},
   "source": [
    "В ходе анализа CNN сетей для параметров регрессора было решено взять следующие:\n",
    "    1. Количество фильтров в каждом слое\n",
    "    2. Размер ядра свертки\n",
    "    3. Количество слоев\n",
    "    4. Количество выходных классов\n",
    "    5. Padding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "n=2\n",
    "m=2\n",
    "l=4  # количество слоев\n",
    "classes=10\n",
    "padding=[\"valid\",\"same\"]\n",
    "data={}\n",
    "df = pd.DataFrame(data)\n",
    "for k in range(l):\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            for ind_p, p in enumerate(padding):\n",
    "                for c in range(2,classes,1):\n",
    "                    model = models.Sequential()\n",
    "                    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "                    filters=(16*2**i)  #количество фильтров\n",
    "                    kernel_square=(j+1)**2 # площадь ядра свертки\n",
    "                    n_layers=k+1   # количество слоев\n",
    "                    for _ in range(k):\n",
    "                        model.add(layers.Conv2D(4*2**i, j+1, j+1, activation='relu'))\n",
    "                        model.add(layers.MaxPooling2D((2, 2)))\n",
    "                    \n",
    "                \n",
    "                    model.add(layers.Flatten())\n",
    "                    model.add(layers.Dense(64, activation='relu'))\n",
    "                    model.add(layers.Dense(c))\n",
    "                    \n",
    "                    average_time=0\n",
    "                \n",
    "                    for _ in range(10):\n",
    "                        start = time.time() ## точка отсчета времени\n",
    "                        test_loss = model.predict(test_images[:5])\n",
    "                        end = time.time() - start ## собственно время работы программы\n",
    "                        average_time+=end\n",
    "                    average_time/=10\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "            \n",
    "                    new_row = {'filters': filters, 'kernal_square': kernel_square,'n_layers': n_layers, 'padding': ind_p, 'out_classes': c, 'time': average_time}\n",
    "            \n",
    "                    df = df.append(new_row, ignore_index=True)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cdc433",
   "metadata": {},
   "source": [
    "Для первого слоя устанавливаем input shape в соответствии с картинками, которые мы подаем на вход. На выходе получаем датасет для регрессора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f666a68",
   "metadata": {},
   "source": [
    "Создание регрессора:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87baa41",
   "metadata": {},
   "source": [
    "Для начала необходимо взять датасет из предыдущей задачи и разбить данные на тренировочные и валидационные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('time', axis=1)\n",
    "y = df['time']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee1775",
   "metadata": {},
   "source": [
    "В качестве оченки качества регрессии было решено взять Среднюю квадратичную ошибку, чтобы избежать грубых ошибок в предсказании времени, так как при генерации моделей могли произойти не маленькие отклонения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9341f",
   "metadata": {},
   "source": [
    "Добавление оставшихся необходимых импортов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4923d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ca6c7",
   "metadata": {},
   "source": [
    "Обучение регрессора. В данном скрипте происходит компиляция модели и обучение на 100 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=rmse,\n",
    "    optimizer=Adam(),\n",
    "    metrics=[rmse]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d99c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.ravel(predictions)\n",
    "print(X_test[:10])\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8df97d",
   "metadata": {},
   "source": [
    "Как мы видим в процессе обучения регрессор уменьшает RMSE, а так же не доходит до стадии переобучения. При валидации тестовой выборки не было выявлено существенных отклонений предсказателя. Для получения более качественных результатов стоит уделить больше внимания созданию датасета и первой части задания, а так же \"поиграться\" c выбором оптимизатора, количества слоев, функциями активации и т.п"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4d983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
